\graphicspath{{members/tf/figures/}}

\subsubsection{Calculating Top-View Leaf Area}
\input{members/tf/authors}

In previous steps we used clustering to estimate the fraction of pixels in the image from above that display leave surface. But this value is only a fraction and no area measure jet.\\
To translate that fraction into an area we have to find the total area that the camera observes first. To do that we take a look at the camera setup (figure \ref{fig:setupAbove}) again.
   \begin{figure}[H]
       \centering
       \includegraphics[scale=0.6]{setupAbove.PNG}
       \caption{Setup of the camera above the plant. $\alpha$ denotes the camera's aperture angle in which the image is captured. $\alpha$ and $h_{Camera}$ are known. The orange triangle is used to calculate the observed area.}
       \label{fig:setupAbove}
   \end{figure}
An perpendicular triangle can constructed by bisecting the aperture angle, as shown in figure \ref{fig:setupAbove}.
Furthermore the height of the triangle is $h_{Camera}$, the angle in the upper corner is $\frac{\alpha}{2}$ and the bottom side has a length of half the width of the observed area. The one dimensional width of the observed area, calculated from the triangle needs to be squared, to get the two dimensional area of the ground:
$$A_{Camera} = (2\cdot h_{Camera}\cdot tan(\frac{\alpha}{2}))^2$$

$A_{Camera}$ only needs to be calculated once, as long as the camera parameters don't change. To calculate the area of the observed green, we simply multiply the captured area of the camera with the fraction $p_{Green}$ calculated by the clustering: 

$$A_{Observed} = p_{green}\cdot A_{Camera}$$

\textbf{Note:} This whole process works as long as the camera is set as supposed. A tilted camera would break the results since the used triangle would no longer have a $90^{\circ}$ angle. A tilted camera might also unintentionally capture adjacent plants.\\
\textbf{Model:} The observed plants are relatively small (max 40cm) in relation to the height of the camera (min 2m). Hence the plants can be considered to be flat on the ground, without changing the visible area. This assumption breaks when the plants grow much larger than expected. However, this is pretty uncommon and can be therfore be neglected.

\subsubsection{Tilt angle correction}
\input{members/tf/authors}

The area calculated in the previous section represents the green area as seen from above, which is not the area of the leaves in the canopy we are searching for. That's because the leaves aren't aligned horizontal but tilted and therefore their size is not perfectly captured as seen in figure \ref{fig:tiltedLeaf}. We have to add a correction to the obseved area to estimate the canopy area.\\
   \begin{figure}[H]
       \centering
       \includegraphics[scale=0.6]{tiltedLeaf.PNG}
       \caption{Sideview comparision of an untilted and a tilted leaf. The captured area from above reduces as a leaf gets tilted by an angle $\beta$.}
       \label{fig:tiltedLeaf}
   \end{figure}
The single leaves are assumed to be uncurved planes, therefore the observed area, the real area and the tilt angle $\beta$ form a $90^{\circ}$ triangle in the 2D sideview. Hence:
$$A_{Canopy} \approx \frac{A_{Observed}}{\arccos \langle |\beta |\rangle }$$

the absolute value of $\beta$ is used in this formula, because wether the tilting is upwards and downwards does not effect the visible area. furthermore the mean of $\beta$ is used, since the single tilt angles of the leaves are unknown and hard to estimate. That mean denotes the mean over all plants, not just a single one. However $\langle |\beta |\rangle$ is still hard to estimate, therefore $\arccos \langle |\beta |\rangle$ is replaced by a parameter that will be trained once the model is in use.\\
\textbf{Model: } The leaves are modeled as uncurved planes, which is most likely not true. Nevertheless the transform described in this section is expected to work, because the trained factor is will not only be trained to correct tiltangles but also curvature of the leaves. Using the model will show whether a linear model can learn this transformation. Assuming that each leaf is scaled by a factor, a linear model should do just fine. Coverage of leaves, which might also occure with adjacent leaves and affect the observed area will also be learned by that linear factor.

\subsection{Pipeline B}\label{subsec:pipeline-b}
\input{members/tf/authors}

Pipeline B contributes to the LAI estimation by estimating the plant height.
The Pipeline in figure \ref{fig:pipelineB} shows, how a picture from the side is used to determine the top of the plant. First of all an edge detector is applied on the picture. Then the longest edge (the stake behind the plant) is found. To find the top of the plant a small window slides down the post until it detects green covering the stake. That point will be considered as the top of the plant. From that point and the camera setup the height can be calculated. 

\begin{figure}[H]
   \centering
   \includegraphics[scale=0.9]{pipelineB.PNG}
   \caption{Pipeline to estimate the height of the plant.}
   \label{fig:pipelineB}
\end{figure}

\subsubsection{Height estimation setup}

The camera  is set as seen in figure \ref{fig:setupSide}. The camera is set at a certain height ($h_{camera}$), a certain distance from the plant ($d$) and has a known tilt angle $\alpha$. The camera slides over a rail, that has a constant distance to the plant lanes and a constant height, to make sure the setup stays the same for every plant.

\begin{figure}[H]
   \centering
   \includegraphics[scale=0.6]{setupSide.PNG}
   \caption{Setup of the camera on the side of the plant. $\alpha$ denotes the tilt angle of the camera as its slightly facing down. }
   \label{fig:setupSide}
\end{figure}

Furthermore every plant has a stake that is placed behind the plant from the cameras perspective, this helps the plant grow straight one one hand but is also useful for the procedure described below. it is important that the stake is large enough to exit the top of the camera frame and is as straight as possible.
\subsubsection{Estimating top of plant}
To estimate the plant's tip, the stake must be found first. that is done using edge detection.
\subsubsection{Edge detection}

To detect the edges a simple vertical edge kernel is applied to the whole picture. This results in a picture $I_E$ with high values for areas with vertical edges and low values for other areas. For the next step all pixels per column are summed up to get a horizontal vector $C$ to get the edge density of each column.

$$C_i = \sum_{j=1}^{y_{range}} I_{E,j,i}$$

The goal of this is to find the column(s) where the stake is located, which will create
the longest edge. The problem is, that this won't result in one big value, but an area with
bigger values, because the stake has two sides, creating two edges and the stake might 
be tilted which will spread the high values over a spacial interval.
To still be able to find the post, we transform the horizontal array before searching
for the maximum. 

$$C_{i} = \sum_{j=i-k}^{i+k} C_j$$

That way the biggest edge density, caused by the stake can be found by searching the maximum value in $C$. A reasonable k needs to be tested during implementation and maybe trained later.\\
Once biggest vertical edge is found, a little window of $10\times10$ (larger?/smaller?) pixels is laid on the top of the stake, this is done bay putting it on the top of the picture and the position where the biggest $C$ was found. This might not directly hit the stake, since it might be tilted. To be invariant to little tilts in the stake, a correction is applied. If the window covers mostly grey pixels (stake), the stake is found. A threshold for the amount of of grey pixels needed for the window to be considered mostly grey should be tested once the system is implemented. If the window does not cover mostly grey the areas left and right of the window are searched for grey areas that fulfill the threshold. In detail the window is shifted left and right of the original position until a position is found where the threshold is fulfilled. The search for the top of the stake should be limited by a certain distance from the biggest edge to prevent other stakes from plants in the background to be found.\\
Once the top of the stake is found, the window starts moving down the stake pixel by pixel. After every step the window is tested to fulfill the threshold, if it does, the search continues with the next step. If the threshold is not fulfilled the window does no longer cover the stake, either because the stake is covered by leaves at that height or because the stake is tilted and the window lost track of it by moving straight down. To prevent the window from losing track of the stake while its still uncovered the same correction is applied that was already used to find the top of the plant, the window searches sideways If it doesn't find a grey area on the left or the right it is because the stake is covered by leaves. Hence the top of the plant is found when the correction can't find a grey area near the old position.\\ 
Once the top of the plant is found by the described procedure the coordinates of the pixel where the search lost track of the stake are stored.
\textbf{Invariances:} The approach with the stake was chosen, to be invariant to green in the background of the picture. That way the plants can be planted close to each other without any problem for this procedure, because no other plant will cover the focused plants stake.\\
The procedure is invariant to slightly tilted stakes, since the window is correcting its path every step, but if the stake is tilted to much the top of the stake might not be found. A strongly tilted stake might also affect the results in a negative way since the stake could be entering the plant surface rather from the side than from the top, which would be lower than the top actually is.

\subsubsection{Height estimation}
Once the top of the plant is found in the image, its coordinates need to be translated into the actual height of that plant. To do so we take advantage of our knowledge about the camera setup displayed in figure \ref{fig:estHeight}.
   \begin{figure}[H]
       \centering
       \includegraphics[scale=0.6]{estHeight.PNG}
       \caption{Setup of the camera on the side of the plant. $\alpha$ denotes the tilt angle of the camera as its slightly facing down. $\beta$ denotes the vertical angle between the center of the picture and the top of the plant. }
       \label{fig:estHeight}
   \end{figure}
Once we know the angle $\beta$ we can easily calculate the height of the plant, since we have a $90^{\circ}$ triangle in our setup. The angle $\beta$ is calculated as follows, where $\gamma$ denotes the lens angle, which states the maximum angle the camera captures:\\
   \begin{figure}[H]
       \centering
       \includegraphics[scale=0.6]{getTopAngle.PNG}
       \caption{$\Delta y$ denotes the vertical distance between the center and the top of the plant in pixels (can be negative if the top is below the center). $y_{range}$ denotes the vertical resolution of the picture.}
       \label{fig:getTopAngle}
   \end{figure}
$$\beta = \frac{\Delta y}{(\frac{y_{range}}{2})}\gamma$$
\textbf{Note:} This works well as long as the picture is not distorted by the lens.
Thus it's suggested to not use a wide angle lens, since it will distort the image
- unlike regular lenses.\\
Once we know $\beta$ we can calculate the height of the plant:
$$h_{plant} = h_{camera} - d\cdot tan(\alpha - \beta)$$

\textbf{Model:} The plant model has cone-like shape with a flat frustum on its top.
Hence it is assumed that the first point along the stake that is covered by the plant
is the plant's tip.
Experiments have shown that this will lead to good results, as further described
in the implementation section.\\

\textbf{Invariances:} a slightly tilted stake doesn't affect this method since the top
area of the plant is assumed to be flat. A strong tilt decreases the precision of
the method even if the stake is correctly found, since the stake might enter the
plant more from the side at a lower level below the top.

\subsection{Estimating LAI}\label{subsec:estimating-lai}
\input{members/tf/authors}

\label{section:EstLAI}
After the height of the plant and the canopy area are estimated, they can be used to calculate an estimation for the Leaf Area Index (LAI) which can be used to predict future yield. This combination of the two pipelines is displayed in figure \ref{fig:wholePipeline}.
   \begin{figure}[H]
       \centering
       \includegraphics[scale=0.8]{wholePipeline.PNG}
       \caption{Pipeline of the whole process, including the two previously described pipelines.}
       \label{fig:wholePipeline}
   \end{figure}

To calculate the LAI, the entire leaf area per ground unit must be calculated.
Since the ground area is the same for every plant this would be a linear transform
of the leaf area. This transform would be the same for every plant, thus won't add
information to the value. In section \ref{section:yieldPrediction} the LAI will be
used as an input for a yield estimator. This estimator will be some kind of learning
algorithm using the LAI as source of information. Which means the ground are doesn't
need to be divided. As already described earlier the plant is modeled as a cone with
multiple leave levels (see figure \ref{fig:branchRepetition}).

\begin{figure}[H]
   \centering
   \includegraphics[scale=0.6]{branchRepetition.PNG}
   \caption{Model of the plant (right) consists of multiple levels of leaves with constant distances $\Delta d$ between the levels. The stamp at the bottom of the plant is 5 cm long and has no leaves.}
   \label{fig:branchRepetition}
\end{figure}

The canopy area measured in pipeline A isdescribes the area of the lowest leaf level of the plant, since that level covers the whole visible area from above. Even though the upper levels partly cover the lowest level, the covered leaves have about the same size as the observed and measured ones.\\
The amount of levels can be calculated by $N_{levels} = \frac{h}{\Delta d}+1$.\\ 
The canopy area is modeled as a circle, like all the levels. Thus a radius can be calculated from the area:
$$r = \sqrt{\frac{A}{\pi}}$$
The radii of the upper levels are linearly decreasing. The area on top of the cone would have an area of zero, which makes sense since the original plant doesn't even reach that high (the cone is one level higher than the original plant).\\ Hence:
$$A_{Total} = \sum_{i=1}^{N_{Levels}}(\frac{i}{N_{Levels}}r)^2\pi$$
The distance of branch repetition $\Delta d$ needs to be trained once the model is in use.

\subsection{Yield prediction}
\input{members/tf/authors}\input{members/paz/authors}
\label{section:yieldPrediction}

One of the most important factors for yield over all sorts of crops is described by the photosynthetically active radiation,
short the PAR. The dry matter production correlates to the amount of radiation a plant is able to absorb. \cite{heuvelink1996tomato}.
In our previous design sectionw e motivated the use of the Leaf Area Index as key variable to predict future yield.
In the work of Breda et. al. the LAI is described as the total one‐sided area of leaf tissue per unit ground surface area.\cite{beda:nathalie}
To get the information on the total LAI the plant is divided into a model based of of Acock et. al. , who divided the canopy of a plant
into multiple horizontal layers with equal depth ($\Delta d$). \cite{acock1978contribution}

The dependency is assumed to be a non-linear, meaning there is a nonlinear function $F$ s.t. $$yield = F(LAI)$$. To find that non-linearity, data needs to be gathered first. For complex models more data is needed than for simple models. Thus for the first iteration the dependency is assumed to be linear. The yield will then be predicted by
$$yield = m\cdot LAI + b$$
Once much data is gathered and it turned out that a linear model doesn't provide good
predictions, it is possible to use more complex models for later iterations.\\

\textbf{Reasonable non-linear approaches:}

\begin{itemize}
   \item Function of higher degree
   \item exponential function
   \item logarithmic function
   \item sigmoid function
   \item neural network
   \item other Machiene Learning methods
\end{itemize}
